{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª ADK Application Testing\n",
    "\n",
    "This notebook demonstrates how to test an ADK (Agent Development Kit) application.\n",
    "It covers both local and remote testing, both with Agent Engine and Cloud Run.\n",
    "\n",
    "> **Note**: This notebook assumes that the agent files are stored in the `app` folder. If your agent files are located in a different directory, please update all relevant file paths and references accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-trace --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeehyeok\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\aiplatform\\models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Vertex AI client\n",
    "#LOCATION = \"asia-northeast1\"\n",
    "import json\n",
    "import vertexai\n",
    "LOCATION = \"us-central1\"\n",
    "PROJECT_ID = \"sandbox-373102\"\n",
    "# Set to None to auto-detect from ./deployment_metadata.json, or specify manually\n",
    "#AGENT_ENGINE_ID = None\n",
    "AGENT_ENGINE_ID = \"5491845076462075904\"\n",
    "if AGENT_ENGINE_ID != None:\n",
    "    REASONING_ENGINE_ID = f\"projects/{PROJECT_ID}/locations/{LOCATION}/reasoningEngines/{AGENT_ENGINE_ID}\"\n",
    "else:\n",
    "    try:\n",
    "        with open(\"../deployment_metadata.json\") as f:\n",
    "            metadata = json.load(f)\n",
    "            REASONING_ENGINE_ID = metadata.get(\"remote_agent_engine_id\")\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass\n",
    "    \n",
    "client = vertexai.Client(\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Engine\n",
    "See more documentation at [Agent Engine Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using REASONING_ENGINE_ID: projects/sandbox-373102/locations/us-central1/reasoningEngines/5491845076462075904\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using REASONING_ENGINE_ID: {REASONING_ENGINE_ID}\")\n",
    "# Get the existing agent engine\n",
    "remote_agent_engine = client.agent_engines.get(name=REASONING_ENGINE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3458657036558925824',\n",
       " 'userId': 'test',\n",
       " 'appName': '5491845076462075904',\n",
       " 'lastUpdateTime': 1762415608.231875,\n",
       " 'events': [],\n",
       " 'state': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = await remote_agent_engine.async_create_session(user_id=\"test\")\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send test query #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {'parts': [{'thought_signature': 'CpkCAePx_14yl36WM9oim0QtN2L6QDv6zRol0-NfEOeyTLxyfh_P78G80SnhGlvlwpr1ahoZijYF3-ZWloR27yoqvTtfaKJstwxePJEDuYfGepk-OID71s2DxebVAnOpvWGl5rKcmNDC16OpgAixyNBU9hLi94ZVzgtNBVhmEGYeu_sBVKjC6vDGLTtJt7ouo9UmSZHEYeygxYEGxLj3gTslSFH0NeYe04VFX5T3mSYjj9fa0OHtNF4dw8jg1_t7Ocn1w7aMGzbsEtGOrOX4OS4oKijevgsdSvcz1uUV0e0DcJtwZcVYBbmuTUMqkRpjN59q9Rpc-IUn_4x3Dkr2op5SaslGbCq4sdAT5OPV-IpSy4475HQBhROQJD0=', 'function_call': {'id': 'adk-559ca127-7a20-4892-b7f4-0e008c5d4c4c', 'args': {'query': 'San Francisco'}, 'name': 'get_weather'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 6, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 6}], 'prompt_token_count': 156, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 156}], 'thoughts_token_count': 57, 'total_token_count': 219, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -1.244869073232015, 'invocation_id': 'e-4ef7e533-cb2d-4169-8bb2-481625162f58', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': '1148cfde-0f66-4f16-920b-90a8f6d2f815', 'timestamp': 1762415618.85888}\n",
      "{'content': {'parts': [{'function_response': {'id': 'adk-559ca127-7a20-4892-b7f4-0e008c5d4c4c', 'name': 'get_weather', 'response': {'result': \"It's 60 degrees and foggy.\"}}}], 'role': 'user'}, 'invocation_id': 'e-4ef7e533-cb2d-4169-8bb2-481625162f58', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': 'd02ca67d-e001-4138-af23-0082cf28e79a', 'timestamp': 1762415619.838186}\n",
      "{'content': {'parts': [{'text': \"It's 60 degrees and foggy in San Francisco.\"}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 13, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 13}], 'prompt_token_count': 176, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 231}], 'total_token_count': 189, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.009963872341009287, 'invocation_id': 'e-4ef7e533-cb2d-4169-8bb2-481625162f58', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '7c8bb746-e55f-4aab-99b6-be0653d589b1', 'timestamp': 1762415620.222176}\n"
     ]
    }
   ],
   "source": [
    "async for event in remote_agent_engine.async_stream_query(\n",
    "    message=\"hi! what's the weather in San francisco?\", user_id=\"test\", session_id = session['id']\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send test query #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': {'parts': [{'thought_signature': 'Co0CAePx_14XTMiOqV_Zm4psj5EH9VQndqGlSBUGNA0loGPOJ_MKxPxkkEqztDFl69kMPEarwXau5h5hLMlEqZ_SlJHLwGISZwVh2y862ZBGq8lBiNq8UNr95o_dcT4DYw5nOHw81n7C46GkqgNgWuAGNyiHEXA0KxFBVx1pvNRl3wn4TFpr95y_YM8e23YmyTcMPZkQAXJDOEFmyHOTZ9-ywZeH9NdoF3wJ4iDYRLkYfEn5hRY2CMz4EZfriEGp3q3PW84iknkY0Pwe2eAwVU5S60KAplHU6vgVyp75imTxElNqaCJQp8Xjth3oFHE9WbfllvGDkup3BiDhDu9YxesTqVM0heb1VeuhqBMbzpE=', 'function_call': {'id': 'adk-22828ffb-9142-47d6-8952-516fc5fe6cee', 'args': {'query': 'Chicago'}, 'name': 'get_weather'}}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 5, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 5}], 'prompt_token_count': 199, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 254}], 'thoughts_token_count': 55, 'total_token_count': 259, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -0.2066568374633789, 'invocation_id': 'e-cd09bae6-d968-46f9-b24b-a8250e746573', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'long_running_tool_ids': [], 'id': '9fbe5051-b34b-48ed-9d3a-cfc34dce06dd', 'timestamp': 1762415622.734833}\n",
      "{'content': {'parts': [{'function_response': {'id': 'adk-22828ffb-9142-47d6-8952-516fc5fe6cee', 'name': 'get_weather', 'response': {'result': \"It's 90 degrees and sunny.\"}}}], 'role': 'user'}, 'invocation_id': 'e-cd09bae6-d968-46f9-b24b-a8250e746573', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': 'af99e2ee-200d-4c2f-a1c0-34f5f777256e', 'timestamp': 1762415623.498764}\n",
      "{'content': {'parts': [{'text': \"It's 90 degrees and sunny in Chicago.\"}], 'role': 'model'}, 'finish_reason': 'STOP', 'usage_metadata': {'candidates_token_count': 12, 'candidates_tokens_details': [{'modality': 'TEXT', 'token_count': 12}], 'prompt_token_count': 218, 'prompt_tokens_details': [{'modality': 'TEXT', 'token_count': 326}], 'total_token_count': 230, 'traffic_type': 'ON_DEMAND'}, 'avg_logprobs': -3.1031234054050096e-05, 'invocation_id': 'e-cd09bae6-d968-46f9-b24b-a8250e746573', 'author': 'root_agent', 'actions': {'state_delta': {}, 'artifact_delta': {}, 'requested_auth_configs': {}, 'requested_tool_confirmations': {}}, 'id': '5279e531-f83c-4a41-853d-7869ffacd537', 'timestamp': 1762415623.864199}\n"
     ]
    }
   ],
   "source": [
    "async for event in remote_agent_engine.async_stream_query(\n",
    "    message=\"hi! what's the weather in chicago?\", user_id=\"test\", session_id = session['id']\n",
    "):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_agent_engine.register_feedback(\n",
    "    feedback={\n",
    "        \"score\": 5,\n",
    "        \"text\": \"Great response!\",\n",
    "        \"invocation_id\": \"test-invocation-123\",\n",
    "        \"user_id\": \"test\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually create memory (By default, memory is not automatically generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = await remote_agent_engine.async_get_session(user_id=\"test\", session_id=session['id'])\n",
    "await remote_agent_engine.async_add_session_to_memory(session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search memory using similarity search by query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await remote_agent_engine.async_search_memory(user_id=\"test\", query=\"San Francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Memory 0 =========\n",
      "Expire: None\n",
      "TTL: None\n",
      "Revision Expire: None\n",
      "Revision TTL: None\n",
      "Disable memory revisions: None\n",
      "Create time: 2025-11-06 07:53:46.010871+00:00\n",
      "Description: None\n",
      "Display name: None\n",
      "Fact: I am interested in the weather in Chicago.\n",
      "Name: projects/1045259343465/locations/us-central1/reasoningEngines/5491845076462075904/memories/7602176776315338752\n",
      "Scope: {'app_name': '5491845076462075904', 'user_id': 'test'}\n",
      "Update time: 2025-11-06 07:53:46.010871+00:00\n",
      "\n",
      "\n",
      "========== Memory 1 =========\n",
      "Expire: None\n",
      "TTL: None\n",
      "Revision Expire: None\n",
      "Revision TTL: None\n",
      "Disable memory revisions: None\n",
      "Create time: 2025-11-06 07:53:46.010049+00:00\n",
      "Description: None\n",
      "Display name: None\n",
      "Fact: I am interested in the weather in San Francisco.\n",
      "Name: projects/1045259343465/locations/us-central1/reasoningEngines/5491845076462075904/memories/2990490757887950848\n",
      "Scope: {'app_name': '5491845076462075904', 'user_id': 'test'}\n",
      "Update time: 2025-11-06 07:53:46.010049+00:00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pager = client.agent_engines.memories.list(name=REASONING_ENGINE_ID)\n",
    "for i, page in enumerate(pager):\n",
    "  print(f\"========== Memory {i} =========\")\n",
    "  print(f\"Expire: {page.expire_time}\")\n",
    "  print(f\"TTL: {page.ttl}\")\n",
    "  print(f\"Revision Expire: {page.revision_expire_time}\")\n",
    "  print(f\"Revision TTL: {page.revision_ttl}\")\n",
    "  print(f\"Disable memory revisions: {page.disable_memory_revisions}\")\n",
    "  print(f\"Create time: {page.create_time}\")\n",
    "  print(f\"Description: {page.description}\")\n",
    "  print(f\"Display name: {page.display_name}\")\n",
    "  print(f\"Fact: {page.fact}\")\n",
    "  print(f\"Name: {page.name}\")\n",
    "  print(f\"Scope: {page.scope}\")\n",
    "  print(f\"Update time: {page.update_time}\")\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Trace data (https://colab.sandbox.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/agent-engine/tracing_agents_in_agent_engine.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[project_id: \"sandbox-373102\"\n",
       " trace_id: \"d5640adfabcb9f9678fb37f63471b0ae\",\n",
       " project_id: \"sandbox-373102\"\n",
       " trace_id: \"f62afe67c1cf5a33fb16d185b5d8fb77\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import trace_v1 as trace\n",
    "client = trace.TraceServiceClient()\n",
    "result = [\n",
    "    r\n",
    "    for r in client.list_traces(\n",
    "        request=trace.types.ListTracesRequest(\n",
    "            project_id=PROJECT_ID,\n",
    "            # Return all traces containing `labels {key: \"openinference.span.kind\" value: \"AGENT\"}`\n",
    "            #filter=\"trace_id:d5640adfabcb9f9678fb37f63471b0ae\",\n",
    "            filter=\"root:invocation\",\n",
    "            order_by=\"start desc\" #Decending order\n",
    "        )\n",
    "    )\n",
    "]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project_id: \"sandbox-373102\"\n",
       "trace_id: \"d5640adfabcb9f9678fb37f63471b0ae\"\n",
       "spans {\n",
       "  span_id: 16420876515183475539\n",
       "  name: \"invocation\"\n",
       "  start_time {\n",
       "    seconds: 1762415622\n",
       "    nanos: 191543824\n",
       "  }\n",
       "  end_time {\n",
       "    seconds: 1762415624\n",
       "    nanos: 585397436\n",
       "  }\n",
       "  labels {\n",
       "    key: \"g.co/agent\"\n",
       "    value: \"opentelemetry-python 1.37.0; google-cloud-trace-exporter 1.9.0\"\n",
       "  }\n",
       "}\n",
       "spans {\n",
       "  span_id: 2837328425360917667\n",
       "  name: \"agent_run [root_agent]\"\n",
       "  start_time {\n",
       "    seconds: 1762415622\n",
       "    nanos: 539343517\n",
       "  }\n",
       "  end_time {\n",
       "    seconds: 1762415624\n",
       "    nanos: 585299689\n",
       "  }\n",
       "  parent_span_id: 16420876515183475539\n",
       "  labels {\n",
       "    key: \"g.co/agent\"\n",
       "    value: \"opentelemetry-python 1.37.0; google-cloud-trace-exporter 1.9.0\"\n",
       "  }\n",
       "}\n",
       "spans {\n",
       "  span_id: 15968098269431560266\n",
       "  name: \"call_llm\"\n",
       "  start_time {\n",
       "    seconds: 1762415622\n",
       "    nanos: 735116612\n",
       "  }\n",
       "  end_time {\n",
       "    seconds: 1762415623\n",
       "    nanos: 630658781\n",
       "  }\n",
       "  parent_span_id: 2837328425360917667\n",
       "  labels {\n",
       "    key: \"gen_ai.usage.output_tokens\"\n",
       "    value: \"5\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.usage.input_tokens\"\n",
       "    value: \"199\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.system\"\n",
       "    value: \"gcp.vertex.agent\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.response.finish_reasons\"\n",
       "    value: \"stop\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.request.model\"\n",
       "    value: \"gemini-2.5-flash\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.session_id\"\n",
       "    value: \"3458657036558925824\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_response\"\n",
       "    value: \"{\\\"content\\\":{\\\"parts\\\":[{\\\"thought_signature\\\":\\\"Co0CAePx_14XTMiOqV_Zm4psj5EH9VQndqGlSBUGNA0loGPOJ_MKxPxkkEqztDFl69kMPEarwXau5h5hLMlEqZ_SlJHLwGISZwVh2y862ZBGq8lBiNq8UNr95o_dcT4DYw5nOHw81n7C46GkqgNgWuAGNyiHEXA0KxFBVx1pvNRl3wn4TFpr95y_YM8e23YmyTcMPZkQAXJDOEFmyHOTZ\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_request\"\n",
       "    value: \"{\\\"model\\\": \\\"gemini-2.5-flash\\\", \\\"config\\\": {\\\"http_options\\\": {\\\"headers\\\": {\\\"x-goog-api-client\\\": \\\"google-adk/1.15.1+remote_reasoning_engine gl-python/3.12.12\\\", \\\"user-agent\\\": \\\"google-adk/1.15.1+remote_reasoning_engine gl-python/3.12.12\\\"}}, \\\"system_instruction\\\": \\\"\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.invocation_id\"\n",
       "    value: \"e-cd09bae6-d968-46f9-b24b-a8250e746573\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.event_id\"\n",
       "    value: \"9fbe5051-b34b-48ed-9d3a-cfc34dce06dd\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"g.co/agent\"\n",
       "    value: \"opentelemetry-python 1.37.0; google-cloud-trace-exporter 1.9.0\"\n",
       "  }\n",
       "}\n",
       "spans {\n",
       "  span_id: 7112202693567896711\n",
       "  name: \"execute_tool get_weather\"\n",
       "  start_time {\n",
       "    seconds: 1762415623\n",
       "    nanos: 498479497\n",
       "  }\n",
       "  end_time {\n",
       "    seconds: 1762415623\n",
       "    nanos: 498914495\n",
       "  }\n",
       "  parent_span_id: 15968098269431560266\n",
       "  labels {\n",
       "    key: \"gen_ai.tool.name\"\n",
       "    value: \"get_weather\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.tool.description\"\n",
       "    value: \"Simulates a web search. Use it get information on weather.\\n\\nArgs:\\n    query: A string containing the location to get weather information for.\\n\\nReturns:\\n    A string with the simulated weather information for the queried location.\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.tool.call.id\"\n",
       "    value: \"adk-22828ffb-9142-47d6-8952-516fc5fe6cee\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.system\"\n",
       "    value: \"gcp.vertex.agent\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.operation.name\"\n",
       "    value: \"execute_tool\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.tool_response\"\n",
       "    value: \"{\\\"result\\\": \\\"It\\'s 90 degrees and sunny.\\\"}\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.tool_call_args\"\n",
       "    value: \"{\\\"query\\\": \\\"Chicago\\\"}\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_response\"\n",
       "    value: \"{}\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_request\"\n",
       "    value: \"{}\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.event_id\"\n",
       "    value: \"af99e2ee-200d-4c2f-a1c0-34f5f777256e\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"g.co/agent\"\n",
       "    value: \"opentelemetry-python 1.37.0; google-cloud-trace-exporter 1.9.0\"\n",
       "  }\n",
       "}\n",
       "spans {\n",
       "  span_id: 8473418980995788571\n",
       "  name: \"call_llm\"\n",
       "  start_time {\n",
       "    seconds: 1762415623\n",
       "    nanos: 864421767\n",
       "  }\n",
       "  end_time {\n",
       "    seconds: 1762415624\n",
       "    nanos: 449544775\n",
       "  }\n",
       "  parent_span_id: 2837328425360917667\n",
       "  labels {\n",
       "    key: \"gen_ai.usage.output_tokens\"\n",
       "    value: \"12\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.usage.input_tokens\"\n",
       "    value: \"218\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.system\"\n",
       "    value: \"gcp.vertex.agent\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.response.finish_reasons\"\n",
       "    value: \"stop\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gen_ai.request.model\"\n",
       "    value: \"gemini-2.5-flash\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.session_id\"\n",
       "    value: \"3458657036558925824\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_response\"\n",
       "    value: \"{\\\"content\\\":{\\\"parts\\\":[{\\\"text\\\":\\\"It\\'s 90 degrees and sunny in Chicago.\\\"}],\\\"role\\\":\\\"model\\\"},\\\"finish_reason\\\":\\\"STOP\\\",\\\"usage_metadata\\\":{\\\"candidates_token_count\\\":12,\\\"candidates_tokens_details\\\":[{\\\"modality\\\":\\\"TEXT\\\",\\\"token_count\\\":12}],\\\"prompt_token_count\\\":218,\\\"prompt_\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.llm_request\"\n",
       "    value: \"{\\\"model\\\": \\\"gemini-2.5-flash\\\", \\\"config\\\": {\\\"http_options\\\": {\\\"headers\\\": {\\\"x-goog-api-client\\\": \\\"google-adk/1.15.1+remote_reasoning_engine gl-python/3.12.12\\\", \\\"user-agent\\\": \\\"google-adk/1.15.1+remote_reasoning_engine gl-python/3.12.12\\\"}}, \\\"system_instruction\\\": \\\"\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.invocation_id\"\n",
       "    value: \"e-cd09bae6-d968-46f9-b24b-a8250e746573\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"gcp.vertex.agent.event_id\"\n",
       "    value: \"5279e531-f83c-4a41-853d-7869ffacd537\"\n",
       "  }\n",
       "  labels {\n",
       "    key: \"g.co/agent\"\n",
       "    value: \"opentelemetry-python 1.37.0; google-cloud-trace-exporter 1.9.0\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_trace(\n",
    "    request=trace.types.GetTraceRequest(\n",
    "            project_id=PROJECT_ID,\n",
    "            trace_id = result[0].trace_id\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing\n",
    "\n",
    "You can import directly the AgentEngineApp class within your environment. \n",
    "To run the agent locally, follow these steps:\n",
    "1. Make sure all required packages are installed in your environment\n",
    "2. The recommended approach is to use the same virtual environment created by the 'uv' tool\n",
    "3. You can set up this environment by running 'make install' from your agent's root directory\n",
    "4. Then select this kernel (.venv folder in your project) in your Jupyter notebook to ensure all dependencies are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you're not using the virtual environment created by uv\n",
    "# import sys\n",
    "# sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from app.agent import root_agent\n",
    "from app.agent_engine_app import AgentEngineApp\n",
    "\n",
    "agent_engine = AgentEngineApp(agent=root_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in agent_engine.async_stream_query(message=\"hi!\", user_id=\"test\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vertexai.Client(\n",
    "    location=LOCATION,\n",
    ")\n",
    "client.agent_engines.delete(\n",
    "    name=REASONING_ENGINE_ID,\n",
    "    force=True, # Optional, if the agent has resources (e.g. sessions, memory)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
